# train_stage_1_contrastive.py
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import transforms
from torchvision.transforms import v2 as T
from tqdm import tqdm
import os
import random
from torchvision.transforms import Compose, RandomApply
from torchvision.transforms import ColorJitter, GaussianBlur, RandomResizedCrop
from models.model_3dcnn import FightDetector3DCNN
from data.dataset import SemanticContrastiveDataset, semantic_collate_fn
from utils.losses import TripletLoss
from configs.default_config import (
    STAGE1_CL_CONFIG,
    DEVICE,
    SEQUENCE_LENGTH,
    IMAGE_HEIGHT,
    IMAGE_WIDTH,
)


def temporal_crop_fn(vid, ratio=0.8):
    T0 = vid.size(0)
    L = max(1, int(T0 * ratio))
    start = random.randint(0, T0 - L)
    return vid[start : start + L]


def main():
    print("--- B·∫Øt ƒë·∫ßu Giai ƒëo·∫°n 1: Contrastive Learning ---")
    config = STAGE1_CL_CONFIG
    os.makedirs(config["save_dir"], exist_ok=True)

    # 1. Augmentation m·∫°nh cho Contrastive Learning
    transform = T.Compose(
        [
            T.Lambda(
                lambda vid: temporal_crop_fn(vid, 0.8)
            ),  # C√°i n√†y c√≥ th·ªÉ gi·ªØ l·∫°i v√¨ n√≥ l√† logic ƒë·∫∑c th√π
            T.RandomHorizontalFlip(p=0.5),  # v2 c√≥ s·∫µn
            T.GaussianBlur(kernel_size=(5, 9)),  # v2 c√≥ s·∫µn
            # T.RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0)), # v2 c√≥ s·∫µn
            # ColorJitter √°p d·ª•ng cho c·∫£ video thay v√¨ t·ª´ng frame
            T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
        ]
    )

    # 2. DataLoader
    # G·ªôp c·∫£ train v√† val ƒë·ªÉ c√≥ nhi·ªÅu d·ªØ li·ªáu h∆°n, v√¨ ta kh√¥ng c·∫ßn nh√£n
    train_path = os.path.join(config["data_path"], "train")
    val_path = os.path.join(config["data_path"], "val")

    dataset = SemanticContrastiveDataset(
        data_dir=train_path,
        sequence_length=SEQUENCE_LENGTH,
        image_height=IMAGE_HEIGHT,
        image_width=IMAGE_WIDTH,
        transform=transform,
    )
    data_loader = DataLoader(
        dataset,
        batch_size=config["batch_size"],
        shuffle=True,
        collate_fn=semantic_collate_fn,
        num_workers=4,
    )
    print(f"ƒê√£ t·∫£i {len(dataset)} m·∫´u video cho Contrastive Learning.")

    # Implement Gradient Accumulation
    physical_batch_size = config["batch_size"]
    virtual_batch_size = config["virtual_batch_size"]

    # ƒê·∫£m b·∫£o chia h·∫øt, n·∫øu kh√¥ng th√¨ c·∫ßn x·ª≠ l√Ω c·∫©n th·∫≠n h∆°n
    assert (
        virtual_batch_size % physical_batch_size == 0
    ), "Virtual batch size ph·∫£i l√† b·ªôi s·ªë c·ªßa physical batch size"

    accumulation_steps = virtual_batch_size // physical_batch_size
    print(
        f"S·∫Ω t√≠ch l≈©y gradient qua {accumulation_steps} b∆∞·ªõc ƒë·ªÉ ƒë·∫°t ƒë∆∞·ª£c virtual batch size l√† {virtual_batch_size}."
    )
    warmup_epochs = config.get("warmup_epochs", 5)

    # 3. Model, Loss, Optimizer
    model = FightDetector3DCNN().to(DEVICE)
    if torch.cuda.device_count() > 1:
        print(f"S·ª≠ d·ª•ng {torch.cuda.device_count()} GPU!")
        model = nn.DataParallel(model, device_ids=[0, 1])
    model.prepare_for_finetuning_classifier(unfreeze_layers=0)
    criterion = TripletLoss(temperature=config["temperature"], device=DEVICE)
    optimizer = optim.AdamW(
        model.CLprj.parameters(), lr=config["learning_rate"], weight_decay=1e-6
    )
    scheduler = optim.lr_scheduler.CosineAnnealingLR(
        optimizer, T_max=len(data_loader) * config["epochs"], eta_min=1e-6
    )

    # 4. Training Loop
    best_loss = float("inf")
    optimizer.zero_grad()

    for epoch in range(config["epochs"]):

        if epoch == warmup_epochs:
            print("--- K·∫øt th√∫c warm-up. Unfreeze backbone v√† ƒëi·ªÅu ch·ªânh LR groups ---")
            model.prepare_for_finetuning_contrastive()  # <-- unfreeze all
            optimizer = optim.AdamW([
                {"params": model.backbone.parameters(), "lr": config.get("backbone_lr", 1e-5)},  # <-- new low LR for backbone
                {"params": model.CLprj.parameters(), "lr": config.get("head_lr", config["learning_rate"])},  # <-- higher LR for head
            ], weight_decay=config.get("weight_decay", 1e-6))
            remaining_iters = len(data_loader) * (config["epochs"] - epoch)
            scheduler = optim.lr_scheduler.CosineAnnealingLR(
                optimizer, T_max=remaining_iters, eta_min=1e-6
            )

        running_loss = 0.0
        progress_bar = tqdm(data_loader, desc=f"Epoch {epoch+1}/{config['epochs']}")

        for i, batch in enumerate(progress_bar):
            if not batch:
                continue

            anchors = batch["anchors"].to(DEVICE)
            positives = batch["positives"].to(DEVICE)
            negatives = batch["negatives"].to(DEVICE)

            emb_anchors, emb_positives, emb_negatives = model(
                (anchors, positives, negatives),
                mode="contrastive",
            )

            loss = criterion(emb_anchors, emb_positives, emb_negatives)

            loss = loss / accumulation_steps

            loss.backward()

            running_loss += loss.item() * accumulation_steps

            if (i + 1) % accumulation_steps == 0:
                optimizer.step()
                scheduler.step()
                optimizer.zero_grad()
            progress_bar.set_postfix(loss=loss.item() * accumulation_steps)

        epoch_loss = running_loss / len(data_loader)
        print(f"Epoch {epoch+1} Loss: {epoch_loss:.4f}")

        if epoch_loss < best_loss:
            best_loss = epoch_loss
            torch.save(
                model.state_dict(), os.path.join(config["save_dir"], "best_model.pt")
            )
            print(f"üéâ Model m·ªõi t·ªët nh·∫•t ƒë∆∞·ª£c l∆∞u v·ªõi loss: {best_loss:.4f}")

    print("Ho√†n t·∫•t Giai ƒëo·∫°n 1 - Contrastive Learning.")


if __name__ == "__main__":
    main()
